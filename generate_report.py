#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•´åˆä¸»ç¨‹åºï¼šè¾“å…¥ç”¨æˆ·å â†’ çˆ¬å–æ•°æ® â†’ è®¡ç®—è¯„åˆ† â†’ ç”Ÿæˆè¯„ä»·ç½‘é¡µ

ä½¿ç”¨æ–¹æ³•:
    python generate_report.py
    æˆ–è€…ä¿®æ”¹ä¸‹é¢çš„ USERNAME å˜é‡
"""

import os
import json
import sqlite3
import asyncio
from dataclasses import asdict
from pathlib import Path

from twitter_crawler import TwitterCrawler
from models.data_model import Account, Tweet
from scoring.engine import calculate, save_tree_structure
from scoring.schema import score_tree
from scoring.normalization_manager import NormalizationManager
from generate_static_html import generate_main_page, generate_user_page, read_json_file

# ==================== é…ç½® ====================
# è¦åˆ†æçš„ Twitter ç”¨æˆ·åï¼ˆä¸å« @ï¼‰
USERNAME = "elonmusk"  # å¯ä»¥ä¿®æ”¹è¿™é‡Œ

# API å¯†é’¥ï¼ˆä»ç¯å¢ƒå˜é‡è·å–ï¼‰
TWEETSCOUT_API_KEY = os.getenv("TWEETSCOUT_API_KEY")
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")

# çˆ¬å–é…ç½®
MAX_TWEETS = 50  # æ¯ä¸ªç”¨æˆ·æœ€å¤šçˆ¬å–å¤šå°‘æ¡æ¨æ–‡
SKIP_COMMENTS = True  # æ˜¯å¦è·³è¿‡è¯„è®ºï¼ˆTrue å¯ä»¥åŠ å¿«é€Ÿåº¦ï¼‰

# è¯„åˆ†é…ç½®
TWEETS_LIMIT = 10  # è¯„åˆ†æ—¶æ¯ä¸ªè´¦å·åªå–å‰ N æ¡æ¨æ–‡ï¼ˆé˜²æ­¢ AI è°ƒç”¨è¿‡å¤šï¼‰

# è¾“å‡ºç›®å½•
DATA_DIR = "data"
OUTPUT_DIR = "outputs"
STATIC_HTML_DIR = "static_html"
# ==============================================


def convert_twitter_db_to_scoring_format(twitter_db_path: str, username: str):
    """
    å°† twitter_crawler ç”Ÿæˆçš„æ•°æ®åº“è½¬æ¢ä¸ºè¯„åˆ†ç³»ç»Ÿéœ€è¦çš„æ ¼å¼
    
    Args:
        twitter_db_path: twitter_crawler ç”Ÿæˆçš„æ•°æ®åº“è·¯å¾„
        username: è¦å¤„ç†çš„ç”¨æˆ·å
        
    Returns:
        (accounts, tweets): Account å’Œ Tweet å¯¹è±¡åˆ—è¡¨
    """
    if not os.path.exists(twitter_db_path):
        raise FileNotFoundError(f"æ•°æ®åº“æ–‡ä»¶ä¸å­˜åœ¨: {twitter_db_path}")
    
    conn = sqlite3.connect(twitter_db_path)
    cursor = conn.cursor()
    
    # ä» users è¡¨è¯»å–ç”¨æˆ·ä¿¡æ¯
    cursor.execute("SELECT user_id, username, followers_count, friends_count, tweets_count, avatar_url, banner_url FROM users WHERE username = ?", (username,))
    user_row = cursor.fetchone()
    
    if not user_row:
        conn.close()
        raise ValueError(f"æœªæ‰¾åˆ°ç”¨æˆ·: {username}")
    
    user_id, username_db, followers_count, friends_count, tweets_count, avatar_url, banner_url = user_row
    
    # ä» tweets è¡¨è¯»å–æ¨æ–‡ï¼ˆè¯»å–æ‰€æœ‰æ¨æ–‡ï¼Œåç»­ä¼šåœ¨è¯„åˆ†æ—¶é™åˆ¶ï¼‰
    cursor.execute("""
        SELECT tweet_id, conversation_id, author_id, author_name, full_text, created_at,
               likes_count, retweets_count, replies_count, views_count,
               in_reply_to_status_id_str, is_quote_status
        FROM tweets 
        WHERE author_id = ?
        ORDER BY created_at DESC
    """, (user_id,))
    
    tweet_rows = cursor.fetchall()
    conn.close()
    
    # è½¬æ¢ä¸º Tweet å¯¹è±¡
    all_tweets = []
    for row in tweet_rows:
        tweet = Tweet(
            tweet_id=row[0] or "",
            author_id=row[2] or "",
            full_text=row[4] or "",
            likes_count=row[6] or 0,
            retweets_count=row[7] or 0,
            replies_count=row[8] or 0,
            views_count=row[9] or 0,
            in_reply_to_status_id_str=row[10] if len(row) > 10 else None,
            is_quote_status=row[11] if len(row) > 11 else 0
        )
        all_tweets.append(tweet)
    
    # é™åˆ¶æ¨æ–‡æ•°é‡ï¼ˆé˜²æ­¢ AI è°ƒç”¨è¿‡å¤šï¼‰- åªç”¨äºè¯„åˆ†
    tweets_for_scoring = all_tweets[:TWEETS_LIMIT] if len(all_tweets) > TWEETS_LIMIT else all_tweets
    
    # åˆ›å»º Account å¯¹è±¡
    # æ³¨æ„ï¼štwitter_crawler çš„ users è¡¨æ²¡æœ‰ description å­—æ®µï¼Œä½¿ç”¨é»˜è®¤å€¼
    account = Account(
        user_id=user_id,
        username=username_db,
        description="",  # twitter_crawler æ²¡æœ‰è¿™ä¸ªå­—æ®µï¼Œä½¿ç”¨ç©ºå­—ç¬¦ä¸²
        followers_count=followers_count or 0,
        friends_count=friends_count or 0,
        tweets_count=tweets_count or 0,
        tweets=tweets_for_scoring  # åªä½¿ç”¨é™åˆ¶åçš„æ¨æ–‡è¿›è¡Œè¯„åˆ†
    )
    
    return [account], all_tweets  # è¿”å›æ‰€æœ‰æ¨æ–‡ç”¨äºä¿å­˜ï¼Œä½†è¯„åˆ†åªç”¨é™åˆ¶åçš„


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("KOL è¯„ä»·æŠ¥å‘Šç”Ÿæˆå™¨")
    print("=" * 60)
    print(f"ç›®æ ‡ç”¨æˆ·: @{USERNAME}")
    print()
    
    # æ£€æŸ¥ API å¯†é’¥
    if not TWEETSCOUT_API_KEY:
        print("âŒ é”™è¯¯: æœªè®¾ç½® TWEETSCOUT_API_KEY ç¯å¢ƒå˜é‡")
        print("   è¯·è®¾ç½®: export TWEETSCOUT_API_KEY='your-key'")
        return 1
    
    if not OPENAI_API_KEY:
        print("âš ï¸  è­¦å‘Š: æœªè®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        print("   è¯„åˆ†åŠŸèƒ½éœ€è¦ OpenAI APIï¼Œè¯·è®¾ç½®: export OPENAI_API_KEY='your-key'")
        print("   ç»§ç»­æ‰§è¡Œ...")
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(DATA_DIR, exist_ok=True)
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    os.makedirs(STATIC_HTML_DIR, exist_ok=True)
    
    twitter_db_path = os.path.join(DATA_DIR, "twitter_data.db")
    
    # ==================== æ­¥éª¤ 1: çˆ¬å–æ•°æ® ====================
    print("\n[æ­¥éª¤ 1/4] çˆ¬å– Twitter æ•°æ®...")
    print("-" * 60)
    
    crawler = TwitterCrawler(
        api_key=TWEETSCOUT_API_KEY,
        output_dir=DATA_DIR,
        db_name="twitter_data.db"
    )
    
    try:
        result = crawler.crawl_user(
            username=USERNAME,
            max_tweets=MAX_TWEETS,
            skip_comments=SKIP_COMMENTS
        )
        
        if not result or result.get('tweets_crawled', 0) == 0:
            print(f"âŒ æœªèƒ½çˆ¬å–åˆ° {USERNAME} çš„æ¨æ–‡æ•°æ®")
            return 1
        
        print(f"âœ… çˆ¬å–å®Œæˆ:")
        print(f"   æ¨æ–‡æ•°: {result['tweets_crawled']}")
        print(f"   è€—æ—¶: {result['elapsed_time']:.2f} ç§’")
        
    except Exception as e:
        print(f"âŒ çˆ¬å–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1
    finally:
        crawler.close()
    
    # ==================== æ­¥éª¤ 2: è½¬æ¢æ•°æ®æ ¼å¼ ====================
    print("\n[æ­¥éª¤ 2/4] è½¬æ¢æ•°æ®æ ¼å¼...")
    print("-" * 60)
    
    try:
        accounts, all_tweets = convert_twitter_db_to_scoring_format(twitter_db_path, USERNAME)
        
        if not accounts or len(accounts) == 0:
            print(f"âŒ æœªæ‰¾åˆ°ç”¨æˆ·æ•°æ®: {USERNAME}")
            return 1
        
        account = accounts[0]
        print(f"âœ… æ•°æ®è½¬æ¢å®Œæˆ:")
        print(f"   ç”¨æˆ·: {account.username}")
        print(f"   ç²‰ä¸æ•°: {account.followers_count:,}")
        print(f"   æ¨æ–‡æ•°: {len(account.tweets)} (ç”¨äºè¯„åˆ†)")
        
        if len(account.tweets) == 0:
            print(f"âš ï¸  è­¦å‘Š: è¯¥ç”¨æˆ·æ²¡æœ‰æ¨æ–‡æ•°æ®ï¼Œæ— æ³•è®¡ç®—è¯„åˆ†")
            return 1
        
    except Exception as e:
        print(f"âŒ æ•°æ®è½¬æ¢å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    # ==================== æ­¥éª¤ 3: è®¡ç®—è¯„åˆ† ====================
    print("\n[æ­¥éª¤ 3/4] è®¡ç®—è¯„åˆ†ï¼ˆè¿™å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼Œå› ä¸ºéœ€è¦è°ƒç”¨ AI APIï¼‰...")
    print("-" * 60)
    print(f"æ³¨æ„: åªä½¿ç”¨å‰ {TWEETS_LIMIT} æ¡æ¨æ–‡è¿›è¡Œè®¡ç®—ï¼Œé˜²æ­¢ AI è°ƒç”¨è¿‡å¤š")
    
    # åˆå§‹åŒ–å½’ä¸€åŒ–ç®¡ç†å™¨ï¼ˆä¼šè‡ªåŠ¨åŠ è½½å·²æœ‰çš„å½’ä¸€åŒ–å‚æ•°ï¼‰
    norm_manager = NormalizationManager()
    norm_manager.load_normalization_params()
    
    try:
        result = asyncio.run(calculate(accounts, score_tree, 
                                      normalization_manager=norm_manager,
                                      save_history=True))
        
        # ä¿å­˜æ•°æ®
        with open(os.path.join(OUTPUT_DIR, "accounts.json"), "w", encoding="utf-8") as f:
            json.dump([asdict(account) for account in accounts], f, ensure_ascii=False, indent=2)
        
        with open(os.path.join(OUTPUT_DIR, "tweets.json"), "w", encoding="utf-8") as f:
            json.dump([asdict(tweet) for tweet in all_tweets], f, ensure_ascii=False, indent=2)
        
        with open(os.path.join(OUTPUT_DIR, "scores.json"), "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2)
        
        save_tree_structure(score_tree, os.path.join(OUTPUT_DIR, "tree_structure.json"))
        
        print("âœ… è¯„åˆ†è®¡ç®—å®Œæˆ:")
        print(f"   è´¦æˆ·æ•°æ®å·²ä¿å­˜åˆ°: {OUTPUT_DIR}/accounts.json")
        print(f"   æ¨æ–‡æ•°æ®å·²ä¿å­˜åˆ°: {OUTPUT_DIR}/tweets.json")
        print(f"   è¯„åˆ†æ•°æ®å·²ä¿å­˜åˆ°: {OUTPUT_DIR}/scores.json")
        print(f"   è¯„åˆ†æ ‘ç»“æ„å·²ä¿å­˜åˆ°: {OUTPUT_DIR}/tree_structure.json")
        
        # æ˜¾ç¤ºæ€»åˆ†
        scores = result.get('scores', {})
        root_score = scores.get('root', [0])[0] if scores.get('root') else 0
        print(f"   ç»¼åˆè¯„åˆ†: {root_score:.2%}")
        
    except Exception as e:
        print(f"âŒ è¯„åˆ†è®¡ç®—å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    # ==================== æ­¥éª¤ 4: ç”Ÿæˆ HTML ç½‘é¡µ ====================
    print("\n[æ­¥éª¤ 4/4] ç”Ÿæˆè¯„ä»·ç½‘é¡µ...")
    print("-" * 60)
    
    try:
        # è¯»å–æ•°æ®
        accounts_data = read_json_file(os.path.join(OUTPUT_DIR, "accounts.json"))
        scores_data = read_json_file(os.path.join(OUTPUT_DIR, "scores.json"))
        tree_structure = read_json_file(os.path.join(OUTPUT_DIR, "tree_structure.json"))
        
        scores = scores_data.get('scores', scores_data)
        comments = scores_data.get('comments', {})
        
        # ç”Ÿæˆä¸»é¡µé¢
        main_html = generate_main_page(accounts_data, scores, tree_structure)
        with open(os.path.join(STATIC_HTML_DIR, 'index.html'), 'w', encoding='utf-8') as f:
            f.write(main_html)
        print(f"âœ… å·²ç”Ÿæˆä¸»é¡µé¢: {STATIC_HTML_DIR}/index.html")
        
        # ç”Ÿæˆç”¨æˆ·è¯¦ç»†é¡µé¢
        for i, account in enumerate(accounts_data):
            user_html = generate_user_page(account, scores, comments, tree_structure, i)
            filename = f'user_{i}.html'
            with open(os.path.join(STATIC_HTML_DIR, filename), 'w', encoding='utf-8') as f:
                f.write(user_html)
            username = account.get('username', 'æœªçŸ¥')
            print(f"âœ… å·²ç”Ÿæˆç”¨æˆ·é¡µé¢: {STATIC_HTML_DIR}/{filename} (ç”¨æˆ·: {username})")
        
        print()
        print("=" * 60)
        print("âœ… å®Œæˆï¼")
        print("=" * 60)
        print(f"ğŸ“„ è¯„ä»·ç½‘é¡µå·²ç”Ÿæˆåˆ°: {os.path.abspath(STATIC_HTML_DIR)}/")
        print(f"   ä¸»é¡µé¢: {STATIC_HTML_DIR}/index.html")
        print(f"   ç”¨æˆ·æŠ¥å‘Š: {STATIC_HTML_DIR}/user_0.html")
        print()
        print("ğŸ’¡ æç¤º: å¯ä»¥ç›´æ¥åœ¨æµè§ˆå™¨ä¸­æ‰“å¼€ HTML æ–‡ä»¶æŸ¥çœ‹")
        
    except Exception as e:
        print(f"âŒ ç”Ÿæˆç½‘é¡µå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())

